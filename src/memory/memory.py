import time
import json
from typing import List, Optional, Dict, Any
from src.core.events import ShortTermMemory, LongTermMemory



class MemoryManager:
    def __init__(self, api_key: Optional[str] = None, 
                 trigger_count: int = 10,
                 max_history_rounds: int = 30):
        """åˆå§‹åŒ–MemoryManager
        
        Args:
            api_key: é˜¿é‡Œç™¾ç‚¼APIå¯†é’¥ï¼Œç”¨äºç”Ÿæˆé•¿æœŸè®°å¿†
            trigger_count: æ¯ç§¯ç´¯å¤šå°‘æ¡çŸ­æœŸè®°å¿†è§¦å‘ä¸€æ¬¡é•¿æœŸè®°å¿†ç”Ÿæˆ
            max_history_rounds: ç”Ÿæˆé•¿æœŸè®°å¿†æ—¶æœ€å¤šä½¿ç”¨å¤šå°‘è½®å¯¹è¯å†å²
        """
        self.memories = []
        self.long_term_memory_data = {
            "summary": "",
            "profile": {},
            "preferences": {},
            "metadata": {}
        }
        self.api_key = api_key
        self.llm_client = None
        self.trigger_count = trigger_count
        self.max_history_rounds = max_history_rounds
        
        # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œåˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        if api_key:
            from openai import OpenAI
            self.llm_client = OpenAI(
                api_key=api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
    
    def add_short_term_memory(self, event: dict):
        """æ·»åŠ å¯¹è¯è®°å½•"""

        memory = ShortTermMemory(
            query=event.get('query', ''),
            response=event.get('response', ''),
            timestamp=event.get('timestamp', time.time()),
            agent=event.get('agent', ''),
            tools_used=event.get('tools_used', []),
            description=f"ç”¨æˆ·æŸ¥è¯¢: {event.get('query', '')} | ç³»ç»Ÿå“åº”: {event.get('response', '')}",
            success=event.get('success', True),
            metadata=event.get('data', {})
        )
        print(f"Adding conversation: memory={memory}")
        self.memories.append(memory)
        
        # æ¯ç§¯ç´¯æŒ‡å®šæ•°é‡çš„çŸ­æœŸè®°å¿†ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€æ¬¡é•¿æœŸè®°å¿†
        if len(self.memories) % self.trigger_count == 0 and len(self.memories) > 0:
            print(f"ğŸ“Š å·²ç´¯ç§¯{len(self.memories)}æ¡çŸ­æœŸè®°å¿†ï¼Œè§¦å‘é•¿æœŸè®°å¿†ç”Ÿæˆ...")
            self._generate_long_term_memory()
    
    def get_short_term_memories(self, max_count: int = 5):
        """è·å–çŸ­æœŸè®°å¿†ï¼ˆé€šç”¨æ¥å£ï¼‰
        """
        try:
            # ç›´æ¥è·å–æœ€è¿‘çš„å¯¹è¯è®°å¿†
            short_memories = self.memories[-max_count:] if self.memories else []
            print(f"Retrieved {len(short_memories)} short term memories")

            return short_memories
        except Exception as e:
            print(f"è·å–çŸ­æœŸè®°å¿†å¤±è´¥: {e}")
            return []
    
    def get_long_term_memory(self, return_raw: bool = False):
        """è·å–é•¿æœŸè®°å¿†ï¼ˆé€šç”¨æ¥å£ï¼‰
        
        Args:
            return_raw: æ˜¯å¦è¿”å›åŸå§‹dictæ ¼å¼ï¼ˆTrueï¼‰è¿˜æ˜¯LongTermMemoryå¯¹è±¡ï¼ˆFalseï¼‰
            
        Returns:
            LongTermMemoryå¯¹è±¡æˆ–dict æˆ– None
        """
        try:
            # å¦‚æœéœ€è¦åŸå§‹æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if return_raw:
                return self.long_term_memory_data
            
            # è½¬æ¢ä¸ºLongTermMemoryå¯¹è±¡
            return LongTermMemory(
                summary=self.long_term_memory_data.get('summary', ''),
                user_profile=self.long_term_memory_data.get('profile', {}),
                preferences=self.long_term_memory_data.get('preferences', {}),
                metadata=self.long_term_memory_data.get('metadata', {})
            )
        except Exception as e:
            print(f"è·å–é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return None
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            'total_memories': len(self.memories),
            'short_term_count': len(self.memories)
        }
    
    def _generate_long_term_memory(self):
        """ä½¿ç”¨æ¨¡å‹ï¼Œä»çŸ­æœŸè®°å¿†ä¸­æŠ½å–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆé•¿æœŸè®°å¿†æ‘˜è¦ã€ç”¨æˆ·ç”»åƒã€åå¥½ç­‰"""
        
        if not self.llm_client:
            print("âš ï¸  æœªé…ç½®LLMå®¢æˆ·ç«¯ï¼Œæ— æ³•ç”Ÿæˆé•¿æœŸè®°å¿†")
            return
        
        if not self.memories:
            print("âš ï¸  æ²¡æœ‰çŸ­æœŸè®°å¿†ï¼Œæ— æ³•ç”Ÿæˆé•¿æœŸè®°å¿†")
            return
        
        try:
            # åªä½¿ç”¨æœ€è¿‘çš„Nè½®å¯¹è¯ï¼Œé¿å…å†å²è¿‡é•¿
            recent_memories = self.memories[-self.max_history_rounds:] if len(self.memories) > self.max_history_rounds else self.memories
            
            # æ„å»ºå¯¹è¯å†å²
            conversations = []
            for memory in recent_memories:
                conversations.append({
                    "user": memory.query,
                    "assistant": memory.response,
                    "timestamp": memory.timestamp
                })
            
            print(f"ğŸ” ä½¿ç”¨æœ€è¿‘{len(recent_memories)}è½®å¯¹è¯ç”Ÿæˆé•¿æœŸè®°å¿†...")
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æå¸ˆï¼Œè´Ÿè´£ä»ç”¨æˆ·çš„å¯¹è¯å†å²ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚

**å¯¹è¯å†å²ï¼š**
{json.dumps(conversations, ensure_ascii=False, indent=2)}

**å½“å‰ç”¨æˆ·ç”»åƒï¼š**
{json.dumps(self.long_term_memory_data.get('profile', {}), ensure_ascii=False, indent=2)}

**å½“å‰ç”¨æˆ·åå¥½ï¼š**
{json.dumps(self.long_term_memory_data.get('preferences', {}), ensure_ascii=False, indent=2)}

**ä»»åŠ¡è¦æ±‚ï¼š**
1. åˆ†æå¯¹è¯å†å²ï¼Œæå–ç”¨æˆ·çš„èº«ä»½ä¿¡æ¯ï¼ˆå¦‚å§“åã€å¹´é¾„ã€èŒä¸šã€ä½å€ã€å®¶åº­æˆå‘˜ç­‰ï¼‰
2. æå–ç”¨æˆ·çš„ä¸ªäººå…´è¶£å’Œå–œå¥½ï¼ˆå¦‚éŸ³ä¹ç±»å‹ã€è¿åŠ¨çˆ±å¥½ã€é¥®é£Ÿåå¥½ç­‰ï¼‰
3. ç”Ÿæˆç”¨æˆ·å¯¹è¯çš„æ€»ä½“æ‘˜è¦
4. å¦‚æœå½“å‰å·²æœ‰ç”¨æˆ·ç”»åƒå’Œåå¥½ä¿¡æ¯ï¼Œè¯·åœ¨ç°æœ‰åŸºç¡€ä¸Šæ›´æ–°å’Œè¡¥å……ï¼Œä¸è¦è¦†ç›–å·²æœ‰çš„å‡†ç¡®ä¿¡æ¯
5. åªæå–å¯¹è¯ä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸è¦çŒœæµ‹æˆ–æ¨æ–­

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š**
{{
    "summary": "ç”¨æˆ·å¯¹è¯çš„æ€»ä½“æ‘˜è¦ï¼Œ100å­—ä»¥å†…",
    "profile": {{
        "name": "ç”¨æˆ·å§“åï¼ˆå¦‚æœæåˆ°ï¼‰",
        "age": ç”¨æˆ·å¹´é¾„ï¼ˆå¦‚æœæåˆ°ï¼Œæ•°å­—ç±»å‹ï¼‰,
        "gender": "æ€§åˆ«ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "occupation": "èŒä¸šï¼ˆå¦‚æœæåˆ°ï¼‰",
        "location": "å±…ä½åœ°å€ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "family": ["å®¶åº­æˆå‘˜ä¿¡æ¯"],
        "other_facts": ["å…¶ä»–ä¸ªäººäº‹å®ä¿¡æ¯"]
    }},
    "preferences": {{
        "music": ["éŸ³ä¹ç±»å‹åå¥½"],
        "food": ["é¥®é£Ÿåå¥½"],
        "sports": ["è¿åŠ¨çˆ±å¥½"],
        "travel": ["æ—…è¡Œåå¥½"],
        "language": "è¯­è¨€åå¥½",
        "other_interests": ["å…¶ä»–å…´è¶£çˆ±å¥½"]
    }}
}}

æ³¨æ„ï¼š
- å¦‚æœæŸä¸ªå­—æ®µæ²¡æœ‰æåˆ°ï¼Œè¯·è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ã€ç©ºæ•°ç»„æˆ–null
- åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æ
"""
            
            print("ğŸ” æ­£åœ¨ä»çŸ­æœŸè®°å¿†ä¸­æå–é•¿æœŸè®°å¿†...")
            
            # è°ƒç”¨LLM
            completion = self.llm_client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æç³»ç»Ÿï¼Œæ“…é•¿ä»å¯¹è¯ä¸­æå–ç”¨æˆ·çš„å…³é”®ä¿¡æ¯ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            # è§£æå“åº”
            response_text = completion.choices[0].message.content
            extracted_data = json.loads(response_text)
            
            # åˆå¹¶æ›´æ–°é•¿æœŸè®°å¿†
            self._merge_long_term_memory(extracted_data)
            
            print("âœ… é•¿æœŸè®°å¿†ç”ŸæˆæˆåŠŸ")
            print(f"   æ‘˜è¦: {self.long_term_memory_data.get('summary', '')}")
            print(f"   ç”¨æˆ·ç”»åƒ: {json.dumps(self.long_term_memory_data.get('profile', {}), ensure_ascii=False)}")
            print(f"   åå¥½ä¿¡æ¯: {json.dumps(self.long_term_memory_data.get('preferences', {}), ensure_ascii=False)}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé•¿æœŸè®°å¿†å¤±è´¥: {e}")
    
    def _merge_long_term_memory(self, new_data: Dict[str, Any]):
        """åˆå¹¶æ–°æå–çš„é•¿æœŸè®°å¿†æ•°æ®åˆ°ç°æœ‰æ•°æ®ä¸­
        
        Args:
            new_data: æ–°æå–çš„æ•°æ®
        """
        # æ›´æ–°æ‘˜è¦
        if new_data.get('summary'):
            self.long_term_memory_data['summary'] = new_data['summary']
        
        # åˆå¹¶ç”¨æˆ·ç”»åƒï¼ˆä¸è¦†ç›–å·²æœ‰çš„éç©ºå€¼ï¼‰
        if 'profile' in new_data:
            for key, value in new_data['profile'].items():
                if value and (not self.long_term_memory_data['profile'].get(key) or value != ""):
                    self.long_term_memory_data['profile'][key] = value
        
        # åˆå¹¶åå¥½ä¿¡æ¯ï¼ˆç´¯ç§¯åˆ—è¡¨ï¼Œå»é‡ï¼‰
        if 'preferences' in new_data:
            for key, value in new_data['preferences'].items():
                if isinstance(value, list):
                    # å¯¹äºåˆ—è¡¨ç±»å‹ï¼Œç´¯ç§¯å¹¶å»é‡
                    existing = self.long_term_memory_data['preferences'].get(key, [])
                    if not isinstance(existing, list):
                        existing = []
                    combined = list(set(existing + value))
                    if combined:
                        self.long_term_memory_data['preferences'][key] = combined
                elif value:
                    # å¯¹äºå…¶ä»–ç±»å‹ï¼Œç›´æ¥æ›´æ–°
                    self.long_term_memory_data['preferences'][key] = value
        
        # æ›´æ–°å…ƒæ•°æ®
        self.long_term_memory_data['metadata']['last_update'] = time.time()
        self.long_term_memory_data['metadata']['update_count'] = \
            self.long_term_memory_data['metadata'].get('update_count', 0) + 1


