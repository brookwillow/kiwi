import time
import json
import ollama
import chromadb
from chromadb.config import Settings
from typing import List, Optional, Dict, Any
from src.core.events import ShortTermMemory, LongTermMemory



class MemoryManager:
    def __init__(self, api_key: Optional[str] = None, 
                 trigger_count: int = 10,
                 max_history_rounds: int = 30,
                 embedding_model: str = "bge-m3:latest",
                 db_path: str = "./data/chroma_db",
                 long_term_memory_file: str = "./data/long_term_memory.json"):
        """åˆå§‹åŒ–MemoryManager
        
        Args:
            api_key: é˜¿é‡Œç™¾ç‚¼APIå¯†é’¥ï¼Œç”¨äºç”Ÿæˆé•¿æœŸè®°å¿†
            trigger_count: æ¯ç§¯ç´¯å¤šå°‘æ¡çŸ­æœŸè®°å¿†è§¦å‘ä¸€æ¬¡é•¿æœŸè®°å¿†ç”Ÿæˆ
            max_history_rounds: ç”Ÿæˆé•¿æœŸè®°å¿†æ—¶æœ€å¤šä½¿ç”¨å¤šå°‘è½®å¯¹è¯å†å²
            embedding_model: ollama embeddingæ¨¡å‹åç§°
            db_path: chromadbæ•°æ®åº“å­˜å‚¨è·¯å¾„
            long_term_memory_file: é•¿æœŸè®°å¿†æŒä¹…åŒ–æ–‡ä»¶è·¯å¾„
        """
        self.memories = []
        self.long_term_memory_data = {
            "summary": "",
            "profile": {},
            "preferences": {},
            "metadata": {}
        }
        self.api_key = api_key
        self.llm_client = None
        self.trigger_count = trigger_count
        self.max_history_rounds = max_history_rounds
        self.long_term_memory_file = long_term_memory_file
        
        # å‘é‡æ•°æ®åº“é…ç½®
        self.embedding_model = embedding_model
        self.db_path = db_path
        
        # åŠ è½½å†å²é•¿æœŸè®°å¿†
        self._load_long_term_memory()
        
        # åˆå§‹åŒ–ChromaDB
        self._init_vector_db()
        
        # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œåˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        if api_key:
            from openai import OpenAI
            self.llm_client = OpenAI(
                api_key=api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
    
    def _init_vector_db(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=self.db_path,
                settings=Settings(anonymized_telemetry=False)
            )
            
            # æ£€æŸ¥å¹¶é‡å»ºcollectionï¼ˆå¦‚æœè·ç¦»å‡½æ•°ä¸åŒ¹é…ï¼‰
            try:
                # å°è¯•è·å–ç°æœ‰collection
                existing_short = self.chroma_client.get_collection("short_term_memories")
                # æ£€æŸ¥è·ç¦»å‡½æ•°
                if existing_short.metadata.get("hnsw:space") != "cosine":
                    print("âš ï¸  æ£€æµ‹åˆ°æ—§çš„çŸ­æœŸè®°å¿†collectionä½¿ç”¨L2è·ç¦»ï¼Œåˆ é™¤å¹¶é‡å»º...")
                    self.chroma_client.delete_collection("short_term_memories")
                    existing_short = None
            except:
                existing_short = None
            
            try:
                existing_long = self.chroma_client.get_collection("long_term_memories")
                if existing_long.metadata.get("hnsw:space") != "cosine":
                    print("âš ï¸  æ£€æµ‹åˆ°æ—§çš„é•¿æœŸè®°å¿†collectionä½¿ç”¨L2è·ç¦»ï¼Œåˆ é™¤å¹¶é‡å»º...")
                    self.chroma_client.delete_collection("long_term_memories")
                    existing_long = None
            except:
                existing_long = None
            
            # åˆ›å»ºæˆ–è·å–çŸ­æœŸè®°å¿†collectionï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
            self.short_term_collection = self.chroma_client.get_or_create_collection(
                name="short_term_memories",
                metadata={"hnsw:space": "cosine"}  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            )
            
            # åˆ›å»ºæˆ–è·å–é•¿æœŸè®°å¿†collectionï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
            self.long_term_collection = self.chroma_client.get_or_create_collection(
                name="long_term_memories",
                metadata={"hnsw:space": "cosine"}  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            )
            
            print(f"âœ… å‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ (è·¯å¾„: {self.db_path})")
            print(f"   è·ç¦»ç®—æ³•: ä½™å¼¦ç›¸ä¼¼åº¦ (cosine)")
            print(f"   çŸ­æœŸè®°å¿†æ•°: {self.short_term_collection.count()}")
            print(f"   é•¿æœŸè®°å¿†æ•°: {self.long_term_collection.count()}")
            
        except Exception as e:
            print(f"âŒ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.chroma_client = None
            self.short_term_collection = None
            self.long_term_collection = None
    
    def _generate_embedding(self, text: str) -> Optional[List[float]]:
        """ä½¿ç”¨ollamaç”Ÿæˆæ–‡æœ¬çš„embeddingå‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            embeddingå‘é‡åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            response = ollama.embeddings(
                model=self.embedding_model,
                prompt=text
            )
            return response['embedding']
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆembeddingå¤±è´¥: {e}")
            return None
    
    def add_short_term_memory(self, event: dict):
        """æ·»åŠ å¯¹è¯è®°å½•"""

        memory = ShortTermMemory(
            query=event.get('query', ''),
            response=event.get('response', ''),
            timestamp=event.get('timestamp', time.time()),
            agent=event.get('agent', ''),
            tools_used=event.get('tools_used', []),
            description=f"ç”¨æˆ·æŸ¥è¯¢: {event.get('query', '')} | ç³»ç»Ÿå“åº”: {event.get('response', '')}",
            success=event.get('success', True),
            metadata=event.get('data', {})
        )
        print(f"Adding conversation: memory={memory}")
        self.memories.append(memory)
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        self._store_short_term_memory_to_vector_db(memory)
        
        # æ¯ç§¯ç´¯æŒ‡å®šæ•°é‡çš„çŸ­æœŸè®°å¿†ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€æ¬¡é•¿æœŸè®°å¿†
        if len(self.memories) % self.trigger_count == 0 and len(self.memories) > 0:
            print(f"ğŸ“Š å·²ç´¯ç§¯{len(self.memories)}æ¡çŸ­æœŸè®°å¿†ï¼Œè§¦å‘é•¿æœŸè®°å¿†ç”Ÿæˆ...")
            self._generate_long_term_memory()
    
    def _store_short_term_memory_to_vector_db(self, memory: ShortTermMemory):
        """å°†çŸ­æœŸè®°å¿†å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            memory: çŸ­æœŸè®°å¿†å¯¹è±¡
        """
        if not self.short_term_collection:
            return
        
        try:
            # åªä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢åšå‘é‡åŒ–ï¼ˆå› ä¸ºæˆ‘ä»¬ä¸»è¦åŸºäºç”¨æˆ·æ„å›¾æ£€ç´¢ï¼‰
            # è¿™æ ·ç›¸åŒçš„æŸ¥è¯¢ä¼šæœ‰æ¥è¿‘1.0çš„ç›¸ä¼¼åº¦
            text = memory.query
            
            # ç”Ÿæˆembedding
            embedding = self._generate_embedding(text)
            if not embedding:
                return
            
            # ç”Ÿæˆå”¯ä¸€ID
            memory_id = f"stm_{int(memory.timestamp * 1000)}"
            
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            # documentå­˜å‚¨å®Œæ•´ä¿¡æ¯ç”¨äºå±•ç¤ºï¼Œä½†embeddingåªåŸºäºquery
            self.short_term_collection.add(
                ids=[memory_id],
                embeddings=[embedding],
                documents=[f"ç”¨æˆ·: {memory.query}\nåŠ©æ‰‹: {memory.response}"],  # å®Œæ•´æ–‡æœ¬ç”¨äºå±•ç¤º
                metadatas=[{
                    "query": memory.query,
                    "response": memory.response,
                    "timestamp": memory.timestamp,
                    "agent": memory.agent,
                    "success": memory.success
                }]
            )
            
        except Exception as e:
            print(f"âš ï¸ å­˜å‚¨çŸ­æœŸè®°å¿†åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
    
    def get_short_term_memories(self, max_count: int = 5):
        """è·å–çŸ­æœŸè®°å¿†ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
        
        Args:
            max_count: æœ€å¤šè¿”å›çš„è®°å¿†æ•°é‡
        
        Returns:
            çŸ­æœŸè®°å¿†åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼Œæœ€è¿‘çš„åœ¨åï¼‰
        """
        try:
            # ç›´æ¥è·å–æœ€è¿‘çš„å¯¹è¯è®°å¿†
            short_memories = self.memories[-max_count:] if self.memories else []
            print(f"Retrieved {len(short_memories)} short term memories (by time)")
            return short_memories
        except Exception as e:
            print(f"è·å–çŸ­æœŸè®°å¿†å¤±è´¥: {e}")
            return []
    
    def get_related_short_memories(self, query: str, max_count: int = 5, similarity_threshold: float = 0.7):
        """åŸºäºå‘é‡ç›¸ä¼¼åº¦è·å–ç›¸å…³è®°å¿†ï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬ï¼Œç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
            max_count: æœ€å¤šè¿”å›çš„è®°å¿†æ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤0.7ï¼Œåªè¿”å›ç›¸ä¼¼åº¦è¶…è¿‡æ­¤å€¼çš„è®°å¿†
        
        Returns:
            çŸ­æœŸè®°å¿†åˆ—è¡¨ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œæœ€ç›¸å…³çš„åœ¨å‰ï¼‰ï¼Œå¦‚æœå‘é‡æ•°æ®åº“ä¸å¯ç”¨åˆ™è¿”å›ç©ºåˆ—è¡¨
        """
        try:
            # å¦‚æœå‘é‡æ•°æ®åº“å¯ç”¨ï¼Œä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦å¬å›
            if self.short_term_collection:
                return self._retrieve_memories_by_similarity(
                    query=query,
                    collection=self.short_term_collection,
                    max_count=max_count,
                    similarity_threshold=similarity_threshold
                )
            else:
                print("âš ï¸ å‘é‡æ•°æ®åº“ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []
    
    def _retrieve_memories_by_similarity(self, query: str, collection, max_count: int = 5, 
                                       similarity_threshold: float = 0.7) -> List[ShortTermMemory]:
        """åŸºäºå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢è®°å¿†
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            collection: chromadb collection
            max_count: æœ€å¤šè¿”å›æ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ—¶ï¼Œé˜ˆå€¼è¶Šé«˜è¶Šç›¸ä¼¼
                                 é»˜è®¤0.7è¡¨ç¤ºåªè¿”å›ç›¸ä¼¼åº¦>0.7çš„ç»“æœ
            
        Returns:
            çŸ­æœŸè®°å¿†åˆ—è¡¨
        """
        try:
            # ç”Ÿæˆqueryçš„embedding
            query_embedding = self._generate_embedding(query)
            if not query_embedding:
                print("âš ï¸ æ— æ³•ç”ŸæˆæŸ¥è¯¢embeddingï¼Œä½¿ç”¨æœ€è¿‘è®°å¿†")
                return self.memories[-max_count:] if self.memories else []
            
            # åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢æœ€ç›¸ä¼¼çš„è®°å¿†
            # æŸ¥è¯¢æ›´å¤šç»“æœä»¥ä¾¿è¿‡æ»¤
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=max_count * 2  # æŸ¥è¯¢2å€æ•°é‡ï¼Œä¾¿äºé˜ˆå€¼è¿‡æ»¤åè¿˜æœ‰è¶³å¤Ÿç»“æœ
            )
            
            # è½¬æ¢ä¸ºShortTermMemoryå¯¹è±¡ï¼Œå¹¶åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼
            memories = []
            if results['metadatas'] and results['metadatas'][0] and results['distances']:
                for i, metadata in enumerate(results['metadatas'][0]):
                    distance = results['distances'][0][i]
                    
                    # ChromaDBä½¿ç”¨cosineè·ç¦»æ—¶: ä½™å¼¦ç›¸ä¼¼åº¦ = 1 - ä½™å¼¦è·ç¦»
                    # ä½™å¼¦è·ç¦»èŒƒå›´ [0, 2]ï¼Œä½™å¼¦ç›¸ä¼¼åº¦èŒƒå›´ [-1, 1]
                    # è·ç¦»è¶Šå°è¶Šç›¸ä¼¼
                    similarity = 1 - distance
                    
                    # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
                    if similarity < similarity_threshold:
                        print(f"   â­ï¸  è·³è¿‡ä½ç›¸ä¼¼åº¦è®°å¿†: {metadata.get('query', '')[:30]}... (ç›¸ä¼¼åº¦: {similarity:.4f}, è·ç¦»: {distance:.4f})")
                        continue
                    
                    # å¦‚æœå·²ç»æ”¶é›†å¤Ÿæ•°é‡ï¼Œåœæ­¢
                    if len(memories) >= max_count:
                        break
                    
                    memory = ShortTermMemory(
                        query=metadata.get('query', ''),
                        response=metadata.get('response', ''),
                        timestamp=metadata.get('timestamp', 0),
                        agent=metadata.get('agent', ''),
                        tools_used=[],
                        description=f"ç”¨æˆ·æŸ¥è¯¢: {metadata.get('query', '')} | ç³»ç»Ÿå“åº”: {metadata.get('response', '')}",
                        success=metadata.get('success', True),
                        metadata={}
                    )
                    memories.append(memory)
            
            print(f"ğŸ” åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢åˆ° {len(memories)} æ¡ç›¸å…³è®°å¿† (é˜ˆå€¼: {similarity_threshold})")
            print(f"   æŸ¥è¯¢å†…å®¹: {query}")
            # æ‰“å°å¬å›çš„å†…å®¹å’Œç›¸ä¼¼åº¦åˆ†æ•°
            if memories:
                for i, memory in enumerate(memories):
                    # éœ€è¦æ‰¾åˆ°è¿™ä¸ªmemoryåœ¨åŸå§‹resultsä¸­çš„ä½ç½®
                    for j, metadata in enumerate(results['metadatas'][0]):
                        if (metadata.get('timestamp') == memory.timestamp and 
                            metadata.get('query') == memory.query):
                            distance = results['distances'][0][j]
                            similarity = 1 - distance
                            print(f"   {i+1}. [{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(memory.timestamp))}] "
                                  f"ç”¨æˆ·: {memory.query[:50]}... | ç›¸ä¼¼åº¦: {similarity:.4f}")
                            break
            return memories
            
        except Exception as e:
            print(f"âš ï¸ å‘é‡æ£€ç´¢å¤±è´¥: {e}ï¼Œä½¿ç”¨æœ€è¿‘è®°å¿†")
            return self.memories[-max_count:] if self.memories else []
    
    def get_long_term_memory(self, return_raw: bool = False):
        """è·å–é•¿æœŸè®°å¿†ï¼ˆé€šç”¨æ¥å£ï¼‰
        
        Args:
            return_raw: æ˜¯å¦è¿”å›åŸå§‹dictæ ¼å¼ï¼ˆTrueï¼‰è¿˜æ˜¯LongTermMemoryå¯¹è±¡ï¼ˆFalseï¼‰
            
        Returns:
            LongTermMemoryå¯¹è±¡æˆ–dict æˆ– None
        """
        try:
            # å¦‚æœéœ€è¦åŸå§‹æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if return_raw:
                return self.long_term_memory_data
            
            # è½¬æ¢ä¸ºLongTermMemoryå¯¹è±¡
            return LongTermMemory(
                summary=self.long_term_memory_data.get('summary', ''),
                user_profile=self.long_term_memory_data.get('profile', {}),
                preferences=self.long_term_memory_data.get('preferences', {}),
                metadata=self.long_term_memory_data.get('metadata', {})
            )
        except Exception as e:
            print(f"è·å–é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return None
        
    def get_related_long_term_memory(self, query: str = "") -> Optional[LongTermMemory]:
        """è·å–ç›¸å…³çš„é•¿æœŸè®°å¿†ï¼ˆç›®å‰ç›´æ¥è¿”å›å…¨éƒ¨é•¿æœŸè®°å¿†ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆé¢„ç•™å‚æ•°ï¼Œå½“å‰æœªä½¿ç”¨ï¼‰
            
        Returns:
            LongTermMemoryå¯¹è±¡ æˆ– None
        """
        try:
            # ç›®å‰ä¸åŸºäºqueryè¿‡æ»¤ï¼Œç›´æ¥è¿”å›å…¨éƒ¨é•¿æœŸè®°å¿†
            return LongTermMemory(
                summary=self.long_term_memory_data.get('summary', ''),
                user_profile=self.long_term_memory_data.get('profile', {}),
                preferences=self.long_term_memory_data.get('preferences', {}),
                metadata=self.long_term_memory_data.get('metadata', {})
            )
        except Exception as e:
            print(f"è·å–ç›¸å…³é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return None
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            'total_memories': len(self.memories),
            'short_term_count': len(self.memories)
        }
    
    def _save_long_term_memory(self):
        """ä¿å­˜é•¿æœŸè®°å¿†åˆ°æ–‡ä»¶"""
        try:
            import os
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.long_term_memory_file), exist_ok=True)
            
            with open(self.long_term_memory_file, 'w', encoding='utf-8') as f:
                json.dump(self.long_term_memory_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ é•¿æœŸè®°å¿†å·²ä¿å­˜åˆ°: {self.long_term_memory_file}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
    
    def _load_long_term_memory(self):
        """ä»æ–‡ä»¶åŠ è½½é•¿æœŸè®°å¿†"""
        try:
            import os
            if os.path.exists(self.long_term_memory_file):
                with open(self.long_term_memory_file, 'r', encoding='utf-8') as f:
                    loaded_data = json.load(f)
                    self.long_term_memory_data = loaded_data
                
                print(f"ğŸ“‚ å·²åŠ è½½å†å²é•¿æœŸè®°å¿†")
                if self.long_term_memory_data.get('summary'):
                    print(f"   æ‘˜è¦: {self.long_term_memory_data['summary'][:50]}...")
                if self.long_term_memory_data.get('profile'):
                    print(f"   ç”¨æˆ·ç”»åƒå­—æ®µ: {len(self.long_term_memory_data['profile'])} ä¸ª")
                if self.long_term_memory_data.get('preferences'):
                    print(f"   ç”¨æˆ·åå¥½å­—æ®µ: {len(self.long_term_memory_data['preferences'])} ä¸ª")
            else:
                print("ğŸ“ æœªæ‰¾åˆ°å†å²é•¿æœŸè®°å¿†ï¼Œå°†åˆ›å»ºæ–°çš„è®°å¿†")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½é•¿æœŸè®°å¿†å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç©ºè®°å¿†")
    
    def _generate_long_term_memory(self):
        """ä½¿ç”¨æ¨¡å‹ï¼Œä»çŸ­æœŸè®°å¿†ä¸­æŠ½å–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆé•¿æœŸè®°å¿†æ‘˜è¦ã€ç”¨æˆ·ç”»åƒã€åå¥½ç­‰"""
        
        if not self.llm_client:
            print("âš ï¸  æœªé…ç½®LLMå®¢æˆ·ç«¯ï¼Œæ— æ³•ç”Ÿæˆé•¿æœŸè®°å¿†")
            return
        
        if not self.memories:
            print("âš ï¸  æ²¡æœ‰çŸ­æœŸè®°å¿†ï¼Œæ— æ³•ç”Ÿæˆé•¿æœŸè®°å¿†")
            return
        
        try:
            # åªä½¿ç”¨æœ€è¿‘çš„Nè½®å¯¹è¯ï¼Œé¿å…å†å²è¿‡é•¿
            recent_memories = self.memories[-self.max_history_rounds:] if len(self.memories) > self.max_history_rounds else self.memories
            
            # æ„å»ºå¯¹è¯å†å²
            conversations = []
            for memory in recent_memories:
                conversations.append({
                    "user": memory.query,
                    "assistant": memory.response,
                    "timestamp": memory.timestamp
                })
            
            print(f"ğŸ” ä½¿ç”¨æœ€è¿‘{len(recent_memories)}è½®å¯¹è¯ç”Ÿæˆé•¿æœŸè®°å¿†...")
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æå¸ˆï¼Œè´Ÿè´£ä»ç”¨æˆ·çš„å¯¹è¯å†å²ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚

**å¯¹è¯å†å²ï¼š**
{json.dumps(conversations, ensure_ascii=False, indent=2)}

**å½“å‰ç”¨æˆ·ç”»åƒï¼š**
{json.dumps(self.long_term_memory_data.get('profile', {}), ensure_ascii=False, indent=2)}

**å½“å‰ç”¨æˆ·åå¥½ï¼š**
{json.dumps(self.long_term_memory_data.get('preferences', {}), ensure_ascii=False, indent=2)}

**ä»»åŠ¡è¦æ±‚ï¼š**
1. åˆ†æå¯¹è¯å†å²ï¼Œæå–ç”¨æˆ·çš„èº«ä»½ä¿¡æ¯ï¼ˆå¦‚å§“åã€å¹´é¾„ã€èŒä¸šã€ä½å€ç­‰ï¼‰
2. æå–å®¶åº­æˆå‘˜ä¿¡æ¯æ—¶ï¼Œæ¯ä¸ªæˆå‘˜å•ç‹¬ä½œä¸ºä¸€ä¸ªå­—æ®µï¼Œæ ¼å¼å¦‚ï¼šfather_nameã€father_phoneã€mother_nameã€mother_phoneç­‰
3. æå–ç”¨æˆ·çš„ä¸ªäººå…´è¶£å’Œå–œå¥½ï¼ˆå¦‚éŸ³ä¹ç±»å‹ã€è¿åŠ¨çˆ±å¥½ã€é¥®é£Ÿåå¥½ç­‰ï¼‰
4. ç”Ÿæˆç”¨æˆ·å¯¹è¯çš„æ€»ä½“æ‘˜è¦
5. å¦‚æœå½“å‰å·²æœ‰ç”¨æˆ·ç”»åƒå’Œåå¥½ä¿¡æ¯ï¼Œè¯·åœ¨ç°æœ‰åŸºç¡€ä¸Šæ›´æ–°å’Œè¡¥å……ï¼Œä¸è¦è¦†ç›–å·²æœ‰çš„å‡†ç¡®ä¿¡æ¯
6. åªæå–å¯¹è¯ä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸è¦çŒœæµ‹æˆ–æ¨æ–­

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š**
{{
    "summary": "å½“å‰æä¾›çš„å¯¹è¯å†å²çš„æ‘˜è¦ï¼Œ100å­—ä»¥å†…",
    "profile": {{
        "name": "ç”¨æˆ·å§“åï¼ˆå¦‚æœæåˆ°ï¼‰",
        "age": ç”¨æˆ·å¹´é¾„ï¼ˆå¦‚æœæåˆ°ï¼Œæ•°å­—ç±»å‹ï¼‰,
        "gender": "æ€§åˆ«ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "occupation": "èŒä¸šï¼ˆå¦‚æœæåˆ°ï¼‰",
        "location": "å±…ä½åœ°å€ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "father_name": "çˆ¶äº²å§“åï¼ˆå¦‚æœæåˆ°ï¼‰",
        "father_phone": "çˆ¶äº²ç”µè¯ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "mother_name": "æ¯äº²å§“åï¼ˆå¦‚æœæåˆ°ï¼‰",
        "mother_phone": "æ¯äº²ç”µè¯ï¼ˆå¦‚æœæåˆ°ï¼‰",
    }},
    "preferences": {{
        "music": ["éŸ³ä¹ç±»å‹åå¥½"],
        "food": ["é¥®é£Ÿåå¥½"],
        "sports": ["è¿åŠ¨çˆ±å¥½"],
        "travel": ["æ—…è¡Œåå¥½"],
        "language": "è¯­è¨€åå¥½",
    }}
}}

æ³¨æ„ï¼š
- å¦‚æœæŸä¸ªå­—æ®µæ²¡æœ‰æåˆ°ï¼Œè¯·è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ã€ç©ºæ•°ç»„æˆ–null
- åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æ
- profileä¸­æ ¹æ®å®é™…å®¶åº­æˆå‘˜çµæ´»æ·»åŠ å­—æ®µï¼Œå¦‚son_nameã€daughter_nameã€wife_nameç­‰
- preferences ä¸­çš„å­—æ®µæ ¹æ®å¯¹è¯å†…å®¹çµæ´»è°ƒæ•´ï¼Œå¯ä»¥æ·»åŠ æ–°çš„å­—æ®µ
- å®¶åº­æˆå‘˜ä¿¡æ¯æ¯ä¸ªæˆå‘˜å•ç‹¬å­˜å‚¨ï¼Œä¸è¦ä½¿ç”¨åˆ—è¡¨
"""
            
            print("ğŸ” æ­£åœ¨ä»çŸ­æœŸè®°å¿†ä¸­æå–é•¿æœŸè®°å¿†...")
            
            # è°ƒç”¨LLM
            completion = self.llm_client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æç³»ç»Ÿï¼Œæ“…é•¿ä»å¯¹è¯ä¸­æå–ç”¨æˆ·çš„å…³é”®ä¿¡æ¯ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            # è§£æå“åº”
            response_text = completion.choices[0].message.content
            extracted_data = json.loads(response_text)
            
            # åˆå¹¶æ›´æ–°é•¿æœŸè®°å¿†
            self._merge_long_term_memory(extracted_data)
            
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            self._store_long_term_memory_to_vector_db()
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_long_term_memory()
            
            print("âœ… é•¿æœŸè®°å¿†ç”ŸæˆæˆåŠŸ")
            print(f"   æ‘˜è¦: {self.long_term_memory_data.get('summary', '')}")
            print(f"   ç”¨æˆ·ç”»åƒ: {json.dumps(self.long_term_memory_data.get('profile', {}), ensure_ascii=False)}")
            print(f"   åå¥½ä¿¡æ¯: {json.dumps(self.long_term_memory_data.get('preferences', {}), ensure_ascii=False)}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé•¿æœŸè®°å¿†å¤±è´¥: {e}")
    
    def _merge_long_term_memory(self, new_data: Dict[str, Any]):
        """åˆå¹¶æ–°æå–çš„é•¿æœŸè®°å¿†æ•°æ®åˆ°ç°æœ‰æ•°æ®ä¸­
        
        Args:
            new_data: æ–°æå–çš„æ•°æ®
        """
        # æ›´æ–°æ‘˜è¦
        if new_data.get('summary'):
            self.long_term_memory_data['summary'] = new_data['summary']
        
        # åˆå¹¶ç”¨æˆ·ç”»åƒï¼ˆä¸è¦†ç›–å·²æœ‰çš„éç©ºå€¼ï¼‰
        if 'profile' in new_data:
            for key, value in new_data['profile'].items():
                if value and (not self.long_term_memory_data['profile'].get(key) or value != ""):
                    self.long_term_memory_data['profile'][key] = value
        
        # åˆå¹¶åå¥½ä¿¡æ¯ï¼ˆç´¯ç§¯åˆ—è¡¨ï¼Œå»é‡ï¼‰
        if 'preferences' in new_data:
            for key, value in new_data['preferences'].items():
                if isinstance(value, list):
                    # å¯¹äºåˆ—è¡¨ç±»å‹ï¼Œç´¯ç§¯å¹¶å»é‡
                    existing = self.long_term_memory_data['preferences'].get(key, [])
                    if not isinstance(existing, list):
                        existing = []
                    combined = list(set(existing + value))
                    if combined:
                        self.long_term_memory_data['preferences'][key] = combined
                elif value:
                    # å¯¹äºå…¶ä»–ç±»å‹ï¼Œç›´æ¥æ›´æ–°
                    self.long_term_memory_data['preferences'][key] = value
        
        # æ›´æ–°å…ƒæ•°æ®
        self.long_term_memory_data['metadata']['last_update'] = time.time()
        self.long_term_memory_data['metadata']['update_count'] = \
            self.long_term_memory_data['metadata'].get('update_count', 0) + 1
    
    def _store_long_term_memory_to_vector_db(self):
        """å°†é•¿æœŸè®°å¿†å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        
        è®¾è®¡ï¼š
        1. æ¸…ç©ºæ‰€æœ‰ç°æœ‰çš„é•¿æœŸè®°å¿†
        2. å°†summaryã€profileå’Œpreferencesçš„æ¯ä¸ªå­—æ®µæ‹†åˆ†ä¸ºç‹¬ç«‹çš„è®°å¿†æ¡ç›®
        3. æ¯ä¸ªæ¡ç›®å•ç‹¬ç”Ÿæˆembeddingï¼Œä¾¿äºç²¾ç¡®æ£€ç´¢
        """
        if not self.long_term_collection:
            return
        
        try:
            # 1. æ¸…ç©ºæ‰€æœ‰ç°æœ‰çš„é•¿æœŸè®°å¿†
            print("ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰é•¿æœŸè®°å¿†...")
            try:
                # è·å–æ‰€æœ‰IDå¹¶åˆ é™¤
                existing = self.long_term_collection.get()
                if existing['ids']:
                    self.long_term_collection.delete(ids=existing['ids'])
                    print(f"   å·²åˆ é™¤ {len(existing['ids'])} æ¡æ—§è®°å¿†")
            except Exception as e:
                print(f"   æ¸…ç©ºå¤±è´¥: {e}")
            
            # 2. å‡†å¤‡æ–°çš„è®°å¿†æ¡ç›®
            memory_items = []
            
            # 2.1 å­˜å‚¨æ‘˜è¦
            summary = self.long_term_memory_data.get('summary', '')
            if summary:
                memory_items.append({
                    'id': 'ltm_summary',
                    'text': f"ç”¨æˆ·å¯¹è¯æ‘˜è¦: {summary}",
                    'metadata': {
                        'type': 'summary',
                        'content': summary,
                        'last_update': self.long_term_memory_data.get('metadata', {}).get('last_update', 0)
                    }
                })
            
            # 2.2 å­˜å‚¨ç”¨æˆ·ç”»åƒçš„æ¯ä¸ªå­—æ®µ
            profile = self.long_term_memory_data.get('profile', {})
            for key, value in profile.items():
                if value:  # åªå­˜å‚¨éç©ºå€¼
                    memory_items.append({
                        'id': f'ltm_profile_{key}',
                        'text': f"ç”¨æˆ·{key}: {value}",
                        'metadata': {
                            'type': 'profile',
                            'field': key,
                            'content': json.dumps(value) if isinstance(value, (list, dict)) else str(value),
                            'last_update': self.long_term_memory_data.get('metadata', {}).get('last_update', 0)
                        }
                    })
            
            # 2.3 å­˜å‚¨ç”¨æˆ·åå¥½çš„æ¯ä¸ªå­—æ®µ
            preferences = self.long_term_memory_data.get('preferences', {})
            for key, value in preferences.items():
                if value:  # åªå­˜å‚¨éç©ºå€¼
                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    if isinstance(value, list):
                        display_value = ', '.join(str(v) for v in value)
                    else:
                        display_value = str(value)
                    
                    memory_items.append({
                        'id': f'ltm_preferences_{key}',
                        'text': f"ç”¨æˆ·åå¥½-{key}: {display_value}",
                        'metadata': {
                            'type': 'preferences',
                            'field': key,
                            'content': json.dumps(value) if isinstance(value, (list, dict)) else str(value),
                            'last_update': self.long_term_memory_data.get('metadata', {}).get('last_update', 0)
                        }
                    })
            
            # 3. æ‰¹é‡ç”Ÿæˆembeddingå¹¶å­˜å‚¨
            if memory_items:
                ids = []
                embeddings = []
                documents = []
                metadatas = []
                
                print(f"ğŸ“ å‡†å¤‡å­˜å‚¨ {len(memory_items)} æ¡é•¿æœŸè®°å¿†å­é¡¹...")
                
                for item in memory_items:
                    # ç”Ÿæˆembedding
                    embedding = self._generate_embedding(item['text'])
                    if embedding:
                        ids.append(item['id'])
                        embeddings.append(embedding)
                        documents.append(item['text'])
                        metadatas.append(item['metadata'])
                
                # æ‰¹é‡æ’å…¥
                if ids:
                    self.long_term_collection.add(
                        ids=ids,
                        embeddings=embeddings,
                        documents=documents,
                        metadatas=metadatas
                    )
                    print(f"âœ… é•¿æœŸè®°å¿†å·²å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ (å…± {len(ids)} æ¡å­é¡¹)")
                    print(f"   - æ‘˜è¦: 1 æ¡")
                    print(f"   - ç”¨æˆ·ç”»åƒ: {len([i for i in metadatas if i['type'] == 'profile'])} æ¡")
                    print(f"   - ç”¨æˆ·åå¥½: {len([i for i in metadatas if i['type'] == 'preferences'])} æ¡")
                else:
                    print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„é•¿æœŸè®°å¿†å¯å­˜å‚¨")
            else:
                print("âš ï¸  é•¿æœŸè®°å¿†æ•°æ®ä¸ºç©º")
            
        except Exception as e:
            print(f"âš ï¸ å­˜å‚¨é•¿æœŸè®°å¿†åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")


