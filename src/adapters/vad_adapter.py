"""
VADæ¨¡å—é€‚é…å™¨

å°†ç°æœ‰çš„ VADå¼•æ“ åŒ…è£…æˆç¬¦åˆæ–°æ¶æ„çš„æ¨¡å—
"""
from typing import Optional, Dict, Any
import numpy as np
from collections import deque

from src.core.interfaces import IVADModule
from src.core.events import Event, EventType, VADEvent as VADEventType
from src.vad import VADFactory, VADConfig, VADResult, VADEvent, VADState
from src.core.message_tracker import get_message_tracker


class VADModuleAdapter(IVADModule):
    """
    VADæ¨¡å—é€‚é…å™¨
    
    èŒè´£ï¼š
    1. åŒ…è£… VADå¼•æ“
    2. æ¥æ”¶éŸ³é¢‘å¸§äº‹ä»¶å¹¶è¿›è¡Œè¯­éŸ³æ£€æµ‹
    3. æ£€æµ‹åˆ°è¯­éŸ³äº‹ä»¶åå‘å¸ƒäº‹ä»¶
    4. ç®¡ç†VADå¸§ç¼“å†²ï¼ˆå¤„ç†å¸§å¤§å°å¯¹é½ï¼‰
    """
    
    def __init__(self, controller, config: Optional[VADConfig] = None):
        """
        åˆå§‹åŒ–VADæ¨¡å—é€‚é…å™¨
        
        Args:
            controller: SystemController å®ä¾‹
            config: VADé…ç½®
        """
        self._controller = controller
        self._config = config
        self._engine = None
        self._running = False
        self._enabled = True
        
        # VADå¸§ç¼“å†²ï¼ˆç”¨äºå¯¹é½å¸§å¤§å°ï¼‰
        self._frame_buffer = []
        self._frame_size = 480  # 30ms @ 16kHzï¼Œä¼šåœ¨åˆå§‹åŒ–åæ›´æ–°
        
        # å½“å‰å¤„ç†çš„æ¶ˆæ¯ID
        self._current_msg_id: Optional[str] = None
        
        # ç»Ÿè®¡
        self._frames_processed = 0
        self._speech_segments = 0
    
    @property
    def name(self) -> str:
        return "vad"
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–VADå¼•æ“"""
        if not self._config:
            print(f"âš ï¸ [{self.name}] æœªæä¾›é…ç½®ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return True
        
        try:
            # åˆ›å»ºVADå¼•æ“
            self._engine = VADFactory.create("webrtc", self._config)
            self._frame_size = self._config.frame_size
            
            print(f"âœ… [{self.name}] åˆå§‹åŒ–æˆåŠŸ")
            print(f"   å¸§å¤§å°: {self._frame_size} æ ·æœ¬ ({self._config.frame_duration_ms}ms)")
            print(f"   æ¿€è¿›åº¦: {self._config.aggressiveness}")
            return True
            
        except Exception as e:
            print(f"âŒ [{self.name}] åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def start(self) -> bool:
        """å¯åŠ¨VADæ£€æµ‹"""
        if not self._engine:
            print(f"âš ï¸ [{self.name}] å¼•æ“æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å¯åŠ¨")
            return True
        
        self._running = True
        self._enabled = True
        print(f"âœ… [{self.name}] å·²å¯åŠ¨")
        return True
    
    def stop(self):
        """åœæ­¢VADæ£€æµ‹"""
        self._running = False
        print(f"âœ… [{self.name}] å·²åœæ­¢")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self._engine = None
        self._frame_buffer.clear()
        print(f"âœ… [{self.name}] èµ„æºå·²æ¸…ç†")
    
    def handle_event(self, event: Event):
        """
        å¤„ç†æ¥è‡ªæ§åˆ¶å™¨çš„äº‹ä»¶
        
        Args:
            event: äº‹ä»¶å¯¹è±¡
        """
        if not self._engine or not self._running:
            return
        
        # å¤„ç†å”¤é†’è¯äº‹ä»¶ - å¯åŠ¨VADå»¶è¿Ÿ
        if event.type == EventType.WAKEWORD_DETECTED:
            if hasattr(self._engine, 'on_wakeword_detected'):
                self._engine.on_wakeword_detected()
        
        # å¤„ç†å”¤é†’è¯é‡ç½®äº‹ä»¶ - é‡ç½®VADå¼•æ“
        elif event.type == EventType.WAKEWORD_RESET:
            self.reset()
        
        # å¤„ç†éŸ³é¢‘å¸§äº‹ä»¶ - åªåœ¨éIDLEçŠ¶æ€å¤„ç†
        elif event.type == EventType.AUDIO_FRAME_READY:
            if self._enabled and self._should_process_audio():
                # å¦‚æœäº‹ä»¶æœ‰msg_idï¼Œè®°å½•ä¸‹æ¥
                if event.msg_id:
                    self._current_msg_id = event.msg_id
                self._process_audio_frame(event.data, event.metadata.get('sample_rate', 16000))
        
        # å¤„ç†ç³»ç»Ÿåœæ­¢äº‹ä»¶
        elif event.type == EventType.SYSTEM_STOP:
            self.stop()
    
    @property
    def is_running(self) -> bool:
        return self._running
    
    def _should_process_audio(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†éŸ³é¢‘å¸§ï¼ˆåªåœ¨éIDLEçŠ¶æ€å¤„ç†ï¼‰"""
        if not self._controller:
            return False
        
        current_state = self._controller.get_current_state()
        if not current_state:
            return False
        
        # åœ¨è¿™äº›çŠ¶æ€ä¸‹å¤„ç†éŸ³é¢‘å¸§ï¼šå”¤é†’åã€ç›‘å¬ä¸­ã€è¯­éŸ³æ£€æµ‹ä¸­
        from src.state_machine import VoiceState
        return current_state in [
            VoiceState.WAKEWORD_DETECTED,
            VoiceState.LISTENING,
            VoiceState.SPEECH_DETECTED,
            VoiceState.RECOGNIZING
        ]
    
    # ==================== IVADModule ä¸“ç”¨æ¥å£ ====================
    
    def process_frame(self, audio_data: Any) -> Optional[dict]:
        """
        å¤„ç†éŸ³é¢‘å¸§
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆint16æ ¼å¼ï¼‰
            
        Returns:
            VADç»“æœ
        """
        if not self._engine:
            return None
        
        try:
            # ç¡®ä¿æ˜¯ int16 æ ¼å¼
            if isinstance(audio_data, np.ndarray):
                if audio_data.dtype != np.int16:
                    audio_data = (audio_data * 32768).astype(np.int16)
            else:
                audio_data = np.array(audio_data, dtype=np.int16)
            
            # å¤„ç†å¸§
            result = self._engine.process_frame(audio_data)
            
            return {
                'is_speech': result.is_speech,
                'event': result.event.value if result.event else 'none',
                'audio_data': result.audio_data,
                'duration_ms': result.duration_ms,
                'state': result.state.value
            }
            
        except Exception as e:
            print(f"âš ï¸ [{self.name}] å¤„ç†å¼‚å¸¸: {e}")
            return None
    
    def reset(self):
        """é‡ç½®VADçŠ¶æ€"""
        if self._engine:
            self._engine.reset()
            self._frame_buffer.clear()
            print(f"ğŸ”„ [{self.name}] çŠ¶æ€å·²é‡ç½®")
    
    def enable(self):
        """å¯ç”¨æ£€æµ‹"""
        self._enabled = True
        print(f"âœ… [{self.name}] æ£€æµ‹å·²å¯ç”¨")
    
    def disable(self):
        """ç¦ç”¨æ£€æµ‹"""
        self._enabled = False
        print(f"â¸ï¸  [{self.name}] æ£€æµ‹å·²ç¦ç”¨")
    
    # ==================== å†…éƒ¨æ–¹æ³• ====================
    
    def _process_audio_frame(self, audio_data: Any, sample_rate: int):
        """
        å¤„ç†éŸ³é¢‘å¸§ï¼ˆå¤„ç†å¸§å¤§å°å¯¹é½ï¼‰
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡
        """
        # ç¡®ä¿æ˜¯ int16 æ ¼å¼
        if isinstance(audio_data, np.ndarray):
            if audio_data.dtype != np.int16:
                audio_int16 = (audio_data * 32768).astype(np.int16)
            else:
                audio_int16 = audio_data
        else:
            audio_int16 = np.array(audio_data, dtype=np.int16)
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self._frame_buffer.extend(audio_int16)
        
        # å½“ç´¯ç§¯äº†è¶³å¤Ÿçš„æ ·æœ¬æ—¶ï¼Œè¿›è¡ŒVADå¤„ç†
        while len(self._frame_buffer) >= self._frame_size:
            # æå–ä¸€ä¸ªVADå¸§
            vad_frame = np.array(self._frame_buffer[:self._frame_size], dtype=np.int16)
            self._frame_buffer = self._frame_buffer[self._frame_size:]
            
            # å¤„ç†VADå¸§
            result = self.process_frame(vad_frame)
            self._frames_processed += 1
            
            if result:
                # å¤„ç†VADäº‹ä»¶
                self._handle_vad_result(result)
    
    def _handle_vad_result(self, result: dict):
        """
        å¤„ç†VADç»“æœ
        
        Args:
            result: VADç»“æœå­—å…¸
        """
        event_type = result.get('event', 'none')
        
        # è¯­éŸ³å¼€å§‹
        if event_type == 'speech_start':
            print(f"\n{'='*60}")
            print(f"ğŸ¤ [{self.name}] è¯­éŸ³å¼€å§‹")
            if self._current_msg_id:
                print(f"   æ¶ˆæ¯ID: {self._current_msg_id}")
            
            # è®°å½•è¿½è¸ª
            if self._current_msg_id:
                tracker = get_message_tracker()
                tracker.add_trace(
                    msg_id=self._current_msg_id,
                    module_name=self.name,
                    event_type="speech_start",
                    input_data={'event': 'audio_frame'}
                )
            
            # å‘å¸ƒäº‹ä»¶
            event = VADEventType(
                EventType.VAD_SPEECH_START,
                source=self.name,
                msg_id=self._current_msg_id
            )
            self._controller.publish_event(event)
            
            # é€šçŸ¥çŠ¶æ€æœº
            from src.state_machine import StateEvent
            self._controller.handle_state_event(StateEvent.SPEECH_START)
        
        # è¯­éŸ³ç»“æŸ
        elif event_type == 'speech_end':
            duration_ms = result.get('duration_ms', 0)
            audio_data = result.get('audio_data')
            
            self._speech_segments += 1
            print(f"\n{'='*60}")
            print(f"ğŸ”‡ VAD: è¯­éŸ³ç»“æŸ [ç¬¬{self._speech_segments}æ®µ] (æ—¶é•¿: {duration_ms:.0f}ms, æ•°æ®: {len(audio_data) if audio_data else 0} bytes)")
            if self._current_msg_id:
                print(f"   æ¶ˆæ¯ID: {self._current_msg_id}")
            print(f"{'='*60}")
            
            # è®°å½•è¿½è¸ª
            if self._current_msg_id:
                tracker = get_message_tracker()
                tracker.add_trace(
                    msg_id=self._current_msg_id,
                    module_name=self.name,
                    event_type="speech_end",
                    output_data={
                        'duration_ms': duration_ms,
                        'audio_length': len(audio_data) if audio_data else 0
                    }
                )
            
            # å‘å¸ƒäº‹ä»¶
            event = VADEventType(
                EventType.VAD_SPEECH_END,
                source=self.name,
                audio_data=audio_data,
                duration_ms=duration_ms,
                msg_id=self._current_msg_id
            )
            self._controller.publish_event(event)
            
            # é€šçŸ¥çŠ¶æ€æœº
            from src.state_machine import StateEvent
            self._controller.handle_state_event(StateEvent.SPEECH_END, {'audio_data': audio_data})
    
    # ==================== ç»Ÿè®¡ä¿¡æ¯ ====================
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'frames_processed': self._frames_processed,
            'speech_segments': self._speech_segments,
            'enabled': self._enabled,
            'is_running': self._running,
            'frame_buffer_size': len(self._frame_buffer),
            'has_engine': self._engine is not None
        }
