"""
åŸºç¡€å·¥å…·Agent - ä½¿ç”¨qwenæ¨¡å‹æ™ºèƒ½é€‰æ‹©å’Œè°ƒç”¨å·¥å…·
"""
from typing import Dict, Any, Optional, List
import json
import os
import asyncio
from openai import OpenAI

from src.agents.base import AgentResponse
from src.core.events import AgentContext
from src.execution.tool_registry import ToolCategory
from src.execution.manager import get_execution_manager


class BaseToolAgent:
    """
    åŸºç¡€å·¥å…·Agent
    ä½¿ç”¨qwenæ¨¡å‹çš„function callingèƒ½åŠ›æ™ºèƒ½é€‰æ‹©å’Œæ‰§è¡Œå·¥å…·
    """
    
    def __init__(
        self,
        name: str,
        description: str,
        capabilities: list[str],
        tool_categories: List[ToolCategory],
        api_key: Optional[str] = None,
        base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    ):
        self.name = name
        self.description = description
        self.capabilities = capabilities
        self.tool_categories = tool_categories
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        self.client = OpenAI(api_key=self.api_key, base_url=base_url) if self.api_key else None
        self.model = "qwen-plus"
        
        # åˆå§‹åŒ–æ‰§è¡Œç®¡ç†å™¨ï¼ˆç»Ÿä¸€å¯¹å¤–æ¥å£ï¼Œå¿…é¡»ç”¨å•ä¾‹ï¼‰
        self.execution_manager = get_execution_manager()
        
        # è·å–å½“å‰agentå¯ç”¨çš„å·¥å…·
        self.available_tools = self._get_available_tools()
    
    def _get_available_tools(self) -> List[Dict]:
        """è·å–å½“å‰agentå¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼‰"""
        tools = []
        for category in self.tool_categories:
            category_tools = self.execution_manager.list_tools(category)
            print(f"ğŸ“¦ {self.name} - ç±»åˆ« {category.value}: æ‰¾åˆ° {len(category_tools)} ä¸ªå·¥å…·")
            
            for tool in category_tools:
                try:
                    # è·å–MCP schema
                    mcp_schema = tool.to_mcp_schema()
                    
                    # è½¬æ¢ä¸ºOpenAI toolsæ ¼å¼
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": mcp_schema.get("name"),
                            "description": mcp_schema.get("description"),
                            "parameters": mcp_schema.get("inputSchema", {})
                        }
                    }
                    
                    # éªŒè¯æ ¼å¼
                    if openai_tool["function"]["name"]:
                        tools.append(openai_tool)
                    else:
                        print(f"âš ï¸  å·¥å…· {tool.name} ç¼ºå°‘åç§°ï¼Œå·²è·³è¿‡")
                        
                except Exception as e:
                    print(f"âš ï¸  å¤„ç†å·¥å…· {tool.name} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
        
        print(f"âœ… ä¸º {self.name} åŠ è½½äº† {len(tools)} ä¸ªæœ‰æ•ˆå·¥å…·")
        return tools
    
    def handle(self, query: str, context: AgentContext = None) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆåŒæ­¥æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨asyncio.runï¼‰
        1. ä½¿ç”¨LLMç†è§£æŸ¥è¯¢æ„å›¾
        2. é€‰æ‹©åˆé€‚çš„å·¥å…·
        3. æ‰§è¡Œå·¥å…·
        4. ç”Ÿæˆå›å¤
        """
        import time
        start_time = time.time()
        print(f"ğŸ” [BaseToolAgent] {self.name}.handle() å¼€å§‹: query='{query}', time={start_time}")
        
        # ä½¿ç”¨asyncio.runæ¥è¿è¡Œå¼‚æ­¥é€»è¾‘
        try:
            result = asyncio.run(self._async_handle(query, context))
            end_time = time.time()
            print(f"ğŸ” [BaseToolAgent] {self.name}.handle() å®Œæˆ: time={end_time}, è€—æ—¶={(end_time-start_time)*1000:.0f}ms")
            return result
        except RuntimeError as e:
            # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨å½“å‰å¾ªç¯
            if "cannot be called from a running event loop" in str(e):
                loop = asyncio.get_event_loop()
                result = loop.run_until_complete(self._async_handle(query, context))
                end_time = time.time()
                print(f"ğŸ” [BaseToolAgent] {self.name}.handle() å®Œæˆ(ä½¿ç”¨å·²æœ‰loop): time={end_time}, è€—æ—¶={(end_time-start_time)*1000:.0f}ms")
                return result
            raise
    
    async def _async_handle(self, query: str, context: AgentContext = None) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å¼‚æ­¥å®ç°
        """
        print(f"ğŸ” [BaseToolAgent] {self.name}._async_handle() å¼€å§‹")
        
        if not self.client:
            return AgentResponse(
                agent=self.name,
                success=False,
                query=query,
                message="æœªé…ç½®APIå¯†é’¥ï¼Œæ— æ³•ä½¿ç”¨æ™ºèƒ½å·¥å…·è°ƒç”¨",
                data={}
            )
        
        try:
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(context)
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]

            print(f"å¯ç”¨å·¥å…·: {[tool['function']['name'] for tool in self.available_tools]}")
            
            # è°ƒç”¨LLMï¼ˆæ”¯æŒfunction callingï¼‰
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.available_tools if self.available_tools else None,
                tool_choice="auto" if self.available_tools else None
            )
            
            message = response.choices[0].message

            print(f"é€‰æ‹©çš„å·¥å…·è°ƒç”¨: {message.tool_calls}" if message.tool_calls else "æ²¡æœ‰é€‰æ‹©å·¥å…·è°ƒç”¨")
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if message.tool_calls:
                return await self._handle_tool_calls(query, message, messages, context)
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å›å¤
                return AgentResponse(
                    agent=self.name,
                    success=True,
                    query=query,
                    message=message.content or "å¥½çš„",
                    data={"no_tool_call": True}
                )
        
        except Exception as e:
            print(f"âŒ {self.name} å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return AgentResponse(
                agent=self.name,
                success=False,
                query=query,
                message=f"å¤„ç†å¤±è´¥: {str(e)}",
                data={"error": str(e)}
            )
    
    async def _handle_tool_calls(
        self,
        query: str,
        message: Any,
        messages: List[Dict],
        context: AgentContext = None
    ) -> AgentResponse:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        tool_results = []
        tools_used = []
        
        # é¦–å…ˆæ·»åŠ  assistant çš„ tool_calls æ¶ˆæ¯ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ tool æ¶ˆæ¯ä¹‹å‰ï¼‰
        messages.append({
            "role": "assistant",
            "content": None,
            "tool_calls": [tool_call.model_dump() for tool_call in message.tool_calls]
        })
        
        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        for tool_call in message.tool_calls:
            tool_name = tool_call.function.name
            tools_used.append(tool_name)
            
            try:
                # è§£æå‚æ•°
                arguments = json.loads(tool_call.function.arguments)
                
                print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                print(f"   å‚æ•°: {arguments}")
                
                # é€šè¿‡ExecutionManageræ‰§è¡Œå·¥å…·
                result = await self.execution_manager.execute_tool(tool_name, **arguments)
                tool_results.append(result)
                
                # æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(result, ensure_ascii=False)
                })
            
            except Exception as e:
                error_msg = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                error_result = {"success": False, "message": error_msg}
                tool_results.append(error_result)
                
                # æ·»åŠ é”™è¯¯ç»“æœ
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(error_result, ensure_ascii=False)
                })
        
        # è®©LLMæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
        try:
            # æ·»åŠ æç¤ºï¼Œè®©LLMç»“åˆè®°å¿†å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå›å¤
            context_reminder = self._build_context_reminder(context)
            if context_reminder:
                messages.append({
                    "role": "system",
                    "content": context_reminder
                })
            
            final_response = self.client.chat.completions.create(
                model=self.model,
                messages=messages
            )
            
            final_message = final_response.choices[0].message.content
            
            return AgentResponse(
                agent=self.name,
                success=all(r.get("success", False) for r in tool_results),
                query=query,
                message=final_message or "å·²å®Œæˆæ“ä½œ",
                data={
                    "tools_used": tools_used,
                    "tool_results": tool_results
                }
            )
        
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæœ€ç»ˆå›å¤å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šç›´æ¥è¿”å›å·¥å…·æ‰§è¡Œç»“æœ
            success_count = sum(1 for r in tool_results if r.get("success", False))
            message = f"å·²æ‰§è¡Œ {len(tools_used)} ä¸ªæ“ä½œï¼Œ{success_count} ä¸ªæˆåŠŸ"
            
            return AgentResponse(
                agent=self.name,
                success=success_count > 0,
                query=query,
                message=message,
                data={
                    "tools_used": tools_used,
                    "tool_results": tool_results
                }
            )
    
    def _build_system_prompt(self, context: AgentContext = None) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        prompt = f"""ä½ æ˜¯{self.description}ã€‚

ä½ çš„èƒ½åŠ›ï¼š
{chr(10).join(f"- {cap}" for cap in self.capabilities)}

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚

é‡è¦æç¤ºï¼š
1. ä»”ç»†ç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
2. å¦‚æœéœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œå¯ä»¥ä¾æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·
3. æ‰§è¡Œå·¥å…·åï¼Œç”¨è‡ªç„¶è¯­è¨€æ€»ç»“ç»“æœç»™ç”¨æˆ·
4. ä¿æŒå›å¤ç®€æ´å‹å¥½ï¼Œä¸è¶…è¿‡100å­—
5. å¦‚æœæ— æ³•å®Œæˆè¯·æ±‚ï¼Œç¤¼è²Œåœ°è¯´æ˜åŸå› 
"""
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context and context.short_term_memories:
            recent_conversations = "\n".join([
                f"ç”¨æˆ·: {m.query}\nåŠ©æ‰‹: {m.response}"
                for m in context.short_term_memories[-3:]
            ])
            prompt += f"\n\nã€é‡è¦ã€‘æœ€è¿‘çš„å¯¹è¯è®°å¿†ï¼ˆè¯·åœ¨é€‰æ‹©å·¥å…·å’Œç”Ÿæˆå›å¤æ—¶å‚è€ƒï¼‰ï¼š\n{recent_conversations}"
            prompt += "\n\nè¯·ç»“åˆä¸Šè¿°å¯¹è¯è®°å¿†æ¥ç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å‚æ•°ã€‚"
        
        return prompt
    
    def _build_context_reminder(self, context: AgentContext = None) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æé†’ï¼Œç”¨äºå·¥å…·è°ƒç”¨åçš„æœ€ç»ˆå›å¤"""
        if not context or not context.short_term_memories:
            return ""
        
        recent_conversations = "\n".join([
            f"ç”¨æˆ·: {m.query}\nåŠ©æ‰‹: {m.response}"
            for m in context.short_term_memories[-3:]
        ])
        
        return f"""è¯·æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœç”Ÿæˆå›å¤ã€‚æ³¨æ„ï¼š
1. ç»“åˆä¹‹å‰çš„å¯¹è¯è®°å¿†ç†è§£ç”¨æˆ·çš„çœŸå®éœ€æ±‚
2. ç”¨è‡ªç„¶ã€å‹å¥½çš„è¯­è¨€æ€»ç»“æ“ä½œç»“æœ
3. å¦‚æœå·¥å…·æ‰§è¡Œç»“æœä¸ç”¨æˆ·æœŸæœ›æœ‰å…³è”ï¼Œè¯·æ˜ç¡®æŒ‡å‡º

å¯¹è¯è®°å¿†ï¼š
{recent_conversations}"""
