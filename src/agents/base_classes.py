"""
AgentåŸºç±»ç»Ÿä¸€å®šä¹‰
æä¾›æ¸…æ™°çš„AgentæŠ½è±¡å±‚æ¬¡ç»“æ„
"""
from __future__ import annotations
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, Optional
from src.core.session_manager import get_session_manager, AgentSession
from src.core.events import AgentResponse, AgentStatus,AgentContext
from src.execution.tool_registry import ToolCategory
from src.execution.manager import get_execution_manager
from openai import OpenAI
import asyncio
import json
from typing import List
import os


# ============================================================================
# æŠ½è±¡åŸºç±» - ç®€å•Agentï¼ˆåŒæ­¥ï¼Œå•è½®å¯¹è¯ï¼‰
# ============================================================================

class SimpleAgentBase(ABC):
    """
    ç®€å•AgentæŠ½è±¡åŸºç±»
    é€‚ç”¨äºï¼šä¸éœ€è¦å¤šè½®å¯¹è¯çš„ç®€å•ä»»åŠ¡
    è¿”å›ï¼šAgentResponse
    """
    
    def __init__(self, name: str, description: str, capabilities: list[str],
                 priority: int = 2):
        self.name = name
        self.description = description
        self.capabilities = capabilities
        self.priority = priority  # ä¼˜å…ˆçº§ï¼ˆ1/2/3ï¼‰
        self.interruptible = (priority < 3)  # ä¼˜å…ˆçº§3ä¸å¯æ‰“æ–­ï¼Œ1å’Œ2å¯æ‰“æ–­
    
    @abstractmethod
    def handle(self, query: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """
        å¤„ç†æŸ¥è¯¢ï¼ˆå­ç±»å®ç°ï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            AgentResponseå¯¹è±¡
        """
        pass
    
    def can_handle(self, query: str) -> bool:
        """é»˜è®¤å®ç°ï¼šé€šè¿‡capabilitiesåˆ¤æ–­"""
        return any(cap.lower() in query.lower() for cap in self.capabilities)


# ============================================================================
# æŠ½è±¡åŸºç±» - ä¼šè¯Agentï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ï¼‰
# ============================================================================

class SessionAgentBase(SimpleAgentBase):
    """
    ä¼šè¯å‹AgentæŠ½è±¡åŸºç±»
    é€‚ç”¨äºï¼šéœ€è¦å¤šè½®å¯¹è¯ã€æ”¶é›†ä¿¡æ¯çš„å¤æ‚ä»»åŠ¡
    è¿”å›ï¼šAgentResponseï¼ˆå¸¦ä¼šè¯ç®¡ç†å­—æ®µï¼‰
    
    æ³¨æ„ï¼šAgent ä¸éœ€è¦å…³å¿ƒ session_idï¼Œsession çš„åˆ›å»ºå’Œç®¡ç†ç”± agent_adapter è´Ÿè´£
    """
    
    def __init__(self, name: str, description: str, capabilities: list[str],
                 priority: int = 2):
        super().__init__(name, description, capabilities, priority)

    def handle(self, query, context = None):
        """Agent ä¸å†å…³å¿ƒ sessionï¼Œåªå…³æ³¨ä¸šåŠ¡é€»è¾‘"""
        return asyncio.run(self._process(query, context))
    
    @abstractmethod
    async def _process(self, query: str, context: Optional[Dict] = None) -> AgentResponse:
        """
        å¤„ç†æŸ¥è¯¢ï¼ˆå­ç±»å®ç°ï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            AgentResponseå¯¹è±¡
            - å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¿”å› status=WAITING_INPUT
            - å¦‚æœå®Œæˆï¼Œè¿”å› status=COMPLETED
            - å¦‚æœå‡ºé”™ï¼Œè¿”å› status=ERROR
        """
        pass
    
    def can_handle(self, query: str) -> bool:
        """é»˜è®¤å®ç°ï¼šé€šè¿‡capabilitiesåˆ¤æ–­"""
        return any(cap.lower() in query.lower() for cap in self.capabilities)


# ============================================================================
# è¾…åŠ©åŸºç±» - å·¥å…·è°ƒç”¨Agent
# ============================================================================

class ToolAgentBase(SimpleAgentBase):
    """
    å·¥å…·è°ƒç”¨AgentæŠ½è±¡åŸºç±»
    ç»§æ‰¿è‡ªSimpleAgentBaseï¼Œä¸“é—¨ç”¨äºé›†æˆLLMå’Œå·¥å…·æ‰§è¡Œ
    
    é€‚ç”¨äºï¼šéœ€è¦è°ƒç”¨å¤–éƒ¨å·¥å…·/APIçš„Agent
    
    å¤šè½®äº¤äº’æ”¯æŒï¼š
    - å½“LLMè®¤ä¸ºä¿¡æ¯ä¸è¶³ã€æ— æ³•è°ƒç”¨å·¥å…·æˆ–æ— æ³•ç¡®å®šå·¥å…·å‚æ•°æ—¶
    - å¯ä»¥è¿”å› AgentStatus.WAITING_INPUT æ¥è¯·æ±‚ç”¨æˆ·è¡¥å……ä¿¡æ¯
    - é€šè¿‡è¿™ç§æ–¹å¼å¯ä»¥è‡ªç„¶åœ°æ„å»ºå¤šè½®å¯¹è¯åœºæ™¯
    - æ— éœ€å•ç‹¬çš„å¤šè½®AgentæŠ½è±¡ï¼ŒToolAgentBaseæœ¬èº«å°±æ”¯æŒçµæ´»çš„äº¤äº’æ¨¡å¼
    """

    def __init__(
        self,
        name: str,
        description: str,
        capabilities: list[str],
        tool_categories: List[ToolCategory],
        priority: int = 2,
        api_key: Optional[str] = None,
        base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    ):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(name, description, capabilities, priority)
        
        self.tool_categories = tool_categories
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        self.client = OpenAI(api_key=self.api_key, base_url=base_url) if self.api_key else None
        self.model = "qwen-plus"
        
        # åˆå§‹åŒ–æ‰§è¡Œç®¡ç†å™¨ï¼ˆç»Ÿä¸€å¯¹å¤–æ¥å£ï¼Œå¿…é¡»ç”¨å•ä¾‹ï¼‰
        self.execution_manager = get_execution_manager()
        
        # è·å–å½“å‰agentå¯ç”¨çš„å·¥å…·
        self.available_tools = self._get_available_tools()

    @property
    def llm_client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        if self._llm_client is None and self.api_key:
            from openai import OpenAI
            self._llm_client = OpenAI(
                api_key=self.api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
        return self._llm_client
    

    
    def _get_available_tools(self) -> List[Dict]:
        """è·å–å½“å‰agentå¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼‰"""
        tools = []
        for category in self.tool_categories:
            category_tools = self.execution_manager.list_tools(category)
            print(f"ğŸ“¦ {self.name} - ç±»åˆ« {category.value}: æ‰¾åˆ° {len(category_tools)} ä¸ªå·¥å…·")
            
            for tool in category_tools:
                try:
                    # è·å–MCP schema
                    mcp_schema = tool.to_mcp_schema()
                    
                    # è½¬æ¢ä¸ºOpenAI toolsæ ¼å¼
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": mcp_schema.get("name"),
                            "description": mcp_schema.get("description"),
                            "parameters": mcp_schema.get("inputSchema", {})
                        }
                    }
                    
                    # éªŒè¯æ ¼å¼
                    if openai_tool["function"]["name"]:
                        tools.append(openai_tool)
                    else:
                        print(f"âš ï¸  å·¥å…· {tool.name} ç¼ºå°‘åç§°ï¼Œå·²è·³è¿‡")
                        
                except Exception as e:
                    print(f"âš ï¸  å¤„ç†å·¥å…· {tool.name} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
        
        print(f"âœ… ä¸º {self.name} åŠ è½½äº† {len(tools)} ä¸ªæœ‰æ•ˆå·¥å…·")
        return tools
    
    def handle(self, query: str, context: AgentContext = None) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆåŒæ­¥æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨asyncio.runï¼‰
        1. ä½¿ç”¨LLMç†è§£æŸ¥è¯¢æ„å›¾
        2. é€‰æ‹©åˆé€‚çš„å·¥å…·
        3. æ‰§è¡Œå·¥å…·
        4. ç”Ÿæˆå›å¤
        """
        # ä½¿ç”¨asyncio.runæ¥è¿è¡Œå¼‚æ­¥é€»è¾‘
        try:
            return asyncio.run(self._async_handle(query, context))
        except RuntimeError as e:
            # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨å½“å‰å¾ªç¯
            if "cannot be called from a running event loop" in str(e):
                loop = asyncio.get_event_loop()
                return loop.run_until_complete(self._async_handle(query, context))
            raise
    
    async def _async_handle(self, query: str, context: AgentContext = None) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å¼‚æ­¥å®ç°
        """
        if not self.client:
            return AgentResponse(
                agent=self.name,
                status=AgentStatus.ERROR,
                query=query,
                message="æœªé…ç½®APIå¯†é’¥ï¼Œæ— æ³•ä½¿ç”¨æ™ºèƒ½å·¥å…·è°ƒç”¨",
                data={}
            )
        
        try:
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(context)
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]

            print(f"å¯ç”¨å·¥å…·: {[tool['function']['name'] for tool in self.available_tools]}")
            
            # è°ƒç”¨LLMï¼ˆæ”¯æŒfunction callingï¼‰
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.available_tools if self.available_tools else None,
                tool_choice="auto" if self.available_tools else None
            )
            
            message = response.choices[0].message

            print(f"é€‰æ‹©çš„å·¥å…·è°ƒç”¨: {message.tool_calls}" if message.tool_calls else "æ²¡æœ‰é€‰æ‹©å·¥å…·è°ƒç”¨")
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if message.tool_calls:
                return await self._handle_tool_calls(query, message, messages, context)
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ŒLLMç›´æ¥å›å¤ï¼ˆå¿…é¡»æ˜¯JSONæ ¼å¼ï¼‰
                response_content = message.content or "{\"need_input\": false, \"message\": \"å¥½çš„\"}"
                
                # è§£æJSONå“åº”ï¼ˆå¼ºåˆ¶è¦æ±‚JSONæ ¼å¼ï¼‰
                parsed_response = self._parse_json_response(response_content)
                
                if parsed_response is None:
                    # JSONè§£æå¤±è´¥ï¼Œè¿”å›é”™è¯¯
                    print(f"âŒ [{self.name}] LLMæœªè¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼: {response_content[:100]}")
                    return AgentResponse(
                        agent=self.name,
                        status=AgentStatus.ERROR,
                        query=query,
                        message="æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•",
                        data={"error": "invalid_json_response", "raw_response": response_content}
                    )
                
                # æ ¹æ®need_inputåˆ¤æ–­çŠ¶æ€
                if parsed_response.get("need_input", True):
                    # LLMæ˜ç¡®è¡¨ç¤ºéœ€è¦ç”¨æˆ·è¾“å…¥
                    print(f"ğŸ”„ [{self.name}] LLMè¡¨ç¤ºéœ€è¦æ›´å¤šä¿¡æ¯")
                    
                    return AgentResponse(
                        agent=self.name,
                        status=AgentStatus.WAITING_INPUT,
                        query=query,
                        message=parsed_response["message"],
                        prompt=parsed_response["message"]
                    )
                else:
                    # ä»»åŠ¡å®Œæˆæˆ–å¯ä»¥ç›´æ¥å›ç­”
                    print(f"âœ… [{self.name}] LLMè¡¨ç¤ºä»»åŠ¡å®Œæˆ")
                    return AgentResponse(
                        agent=self.name,
                        status=AgentStatus.COMPLETED,
                        query=query,
                        message=parsed_response["message"],
                    )
        
        except Exception as e:
            print(f"âŒ {self.name} å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return AgentResponse(
                agent=self.name,
                status=AgentStatus.ERROR,
                query=query,
                message=f"å¤„ç†å¤±è´¥: {str(e)}",
                data={"error": str(e)}
            )
    
    async def _handle_tool_calls(
        self,
        query: str,
        message: Any,
        messages: List[Dict],
        context: AgentContext = None
    ) -> AgentResponse:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        tool_results = []
        tools_used = []
        


        messages.clear()
        messages.append({
            "role": "user",
            "content": query
        })

        # é¦–å…ˆæ·»åŠ  assistant çš„ tool_calls æ¶ˆæ¯ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ tool æ¶ˆæ¯ä¹‹å‰ï¼‰
        messages.append({
            "role": "assistant",
            "content": None,
            "tool_calls": [tool_call.model_dump() for tool_call in message.tool_calls]
        })
        
        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        for tool_call in message.tool_calls:
            tool_name = tool_call.function.name
            tools_used.append(tool_name)
            
            try:
                # è§£æå‚æ•°
                arguments = json.loads(tool_call.function.arguments)
                
                print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                print(f"   å‚æ•°: {arguments}")
                
                # é€šè¿‡ExecutionManageræ‰§è¡Œå·¥å…·
                result = await self.execution_manager.execute_tool(tool_name, **arguments)
                tool_results.append(result)
                
                # æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(result, ensure_ascii=False)
                })
            
            except Exception as e:
                error_msg = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                error_result = {"success": False, "message": error_msg}
                tool_results.append(error_result)
                
                # æ·»åŠ é”™è¯¯ç»“æœ
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(error_result, ensure_ascii=False)
                })
        
        # è®©LLMæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
        try:
            # æ·»åŠ æç¤ºï¼Œè®©LLMç»“åˆè®°å¿†å’Œä¸Šä¸‹æ–‡ç”Ÿæˆå›å¤
            context_reminder = self._build_context_reminder(context)
            if context_reminder:
                messages.append({
                    "role": "system",
                    "content": context_reminder
                })
            
            final_response = self.client.chat.completions.create(
                model=self.model,
                messages=messages
            )

            print(f"ç”Ÿæˆçš„æœ€ç»ˆå›å¤: {final_response.choices[0].message.content}")
            
            final_message = final_response.choices[0].message.content
            
            return AgentResponse(
                agent=self.name,
                status=AgentStatus.COMPLETED,
                query=query,
                message=final_message or "å·²å®Œæˆæ“ä½œ",
                data={
                    "tools_used": tools_used,
                    "tool_results": tool_results
                }
            )
        
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæœ€ç»ˆå›å¤å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šç›´æ¥è¿”å›å·¥å…·æ‰§è¡Œç»“æœ
            success_count = sum(1 for r in tool_results if r.get("success", False))
            message = f"å·²æ‰§è¡Œ {len(tools_used)} ä¸ªæ“ä½œï¼Œ{success_count} ä¸ªæˆåŠŸ"
            
            return AgentResponse(
                agent=self.name,
                status=AgentStatus.ERROR,
                query=query,
                message=message,
                data={
                    "tools_used": tools_used,
                    "tool_results": tool_results
                }
            )
    
    def _build_system_prompt(self, context: AgentContext = None) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        prompt = f"""ä½ æ˜¯{self.description}ã€‚

ä½ çš„èƒ½åŠ›ï¼š
{chr(10).join(f"- {cap}" for cap in self.capabilities)}

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚

é‡è¦æç¤ºï¼š
1. ä»”ç»†ç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
2. å¦‚æœç”¨æˆ·æä¾›çš„ä¿¡æ¯ä¸è¶³ä»¥è°ƒç”¨å·¥å…·ï¼ˆå¦‚ç¼ºå°‘å¿…éœ€å‚æ•°ï¼‰ï¼Œä¸è¦è°ƒç”¨å·¥å…·ï¼Œè€Œæ˜¯è¯¢é—®ç¼ºå¤±çš„ä¿¡æ¯
3. å¦‚æœä½¿ç”¨å·¥å…·éœ€è¦ç”¨æˆ·ç¡®è®¤ï¼Œä¹Ÿè¯·å…ˆè¯¢é—®ç”¨æˆ·
4. å¦‚æœéœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œå¯ä»¥ä¾æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·
5. æ‰§è¡Œå·¥å…·åï¼Œç”¨è‡ªç„¶è¯­è¨€æ€»ç»“ç»“æœç»™ç”¨æˆ·
6. ä¿æŒå›å¤ç®€æ´å‹å¥½ï¼Œä¸è¶…è¿‡100å­—
7. å¦‚æœæ— æ³•å®Œæˆè¯·æ±‚ï¼Œç¤¼è²Œåœ°è¯´æ˜åŸå› 

ã€é‡è¦ã€‘ä½ å¿…é¡»å§‹ç»ˆä»¥JSONæ ¼å¼å›å¤ï¼ˆæ— è®ºä»»ä½•æƒ…å†µï¼‰ï¼š

æ ¼å¼1 - å½“ä¿¡æ¯å……è¶³ï¼Œä»»åŠ¡å®Œæˆæˆ–å¯ä»¥ç›´æ¥å›ç­”æ—¶ï¼š
{{"need_input": false, "message": "ä½ çš„å›å¤å†…å®¹"}}

æ ¼å¼2 - å½“ä¿¡æ¯ä¸è¶³æˆ–è€…éœ€è¦ç”¨æˆ·ç¡®è®¤æ—¶ï¼Œéœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯æ—¶ï¼š
{{"need_input": true, "message": "ä½ è¦è¯¢é—®çš„é—®é¢˜"}}

ç¤ºä¾‹ï¼š
- {{"need_input": false, "message": "å·²ç»å¸®ä½ è®¾ç½®æ¸©åº¦ä¸º25åº¦äº†"}}
- {{"need_input": true, "message": "è¯·é—®ä½ è¦å»å“ªé‡Œï¼Ÿ"}}
- {{"need_input": true, "message": "ç¡®è®¤è¦æ‰§è¡Œå—"}}
- {{"need_input": false, "message": "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å®Œæˆè¿™ä¸ªæ“ä½œ"}}

æ³¨æ„ï¼šå¿…é¡»ä¸¥æ ¼è¿”å›JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ å…¶ä»–æ–‡å­—ã€‚
"""
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context and context.short_term_memories:
            recent_conversations = "\n".join([
                f"ç”¨æˆ·: {m.query}\nåŠ©æ‰‹: {m.response}"
                for m in context.short_term_memories[-3:]
            ])
            prompt += f"\n\nã€é‡è¦ã€‘æœ€è¿‘çš„å¯¹è¯è®°å¿†ï¼ˆè¯·åœ¨é€‰æ‹©å·¥å…·å’Œç”Ÿæˆå›å¤æ—¶å‚è€ƒï¼‰ï¼š\n{recent_conversations}"
            prompt += "\n\nè¯·ç»“åˆä¸Šè¿°å¯¹è¯è®°å¿†æ¥ç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å‚æ•°ã€‚"
        
        return prompt
    
    def _parse_json_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """
        è§£æLLMçš„JSONå“åº”
        
        Args:
            response_text: LLMçš„å“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å­—å…¸ï¼ŒåŒ…å« need_input å’Œ message å­—æ®µ
            å¦‚æœè§£æå¤±è´¥è¿”å› None
        """
        if not response_text:
            return None
        
        # å»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
        text = response_text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()
        
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            data = json.loads(text)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if isinstance(data, dict) and "message" in data:
                # need_input é»˜è®¤ä¸º false
                if "need_input" not in data:
                    data["need_input"] = False
                return data
            else:
                print(f"âš ï¸ JSONæ ¼å¼æ­£ç¡®ä½†ç¼ºå°‘å¿…éœ€å­—æ®µ: {data}")
                return None
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            # å°è¯•æå–JSONï¼ˆå¯èƒ½è¢«åŒ…è£¹åœ¨æ–‡æœ¬ä¸­ï¼‰
            import re
            json_match = re.search(r'\{[^{}]*"message"[^{}]*\}', text)
            if json_match:
                try:
                    data = json.loads(json_match.group())
                    if isinstance(data, dict) and "message" in data:
                        if "need_input" not in data:
                            data["need_input"] = False
                        return data
                except json.JSONDecodeError:
                    pass
        
        return None
    
    def _build_context_reminder(self, context: AgentContext = None) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æé†’ï¼Œç”¨äºå·¥å…·è°ƒç”¨åçš„æœ€ç»ˆå›å¤"""
        if not context or not context.short_term_memories:
            return ""
        
        recent_conversations = "\n".join([
            f"ç”¨æˆ·: {m.query}\nåŠ©æ‰‹: {m.response}"
            for m in context.short_term_memories[-3:]
        ])
        
        return f"""è¯·æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœç”Ÿæˆå›å¤ã€‚æ³¨æ„ï¼š
1. ç»“åˆä¹‹å‰çš„å¯¹è¯è®°å¿†ç†è§£ç”¨æˆ·çš„çœŸå®éœ€æ±‚
2. ç”¨è‡ªç„¶ã€å‹å¥½çš„è¯­è¨€æ€»ç»“æ“ä½œç»“æœ
3. å¦‚æœå·¥å…·æ‰§è¡Œç»“æœä¸ç”¨æˆ·æœŸæœ›æœ‰å…³è”ï¼Œè¯·æ˜ç¡®æŒ‡å‡º

å¯¹è¯è®°å¿†ï¼š
{recent_conversations}

ç”¨æˆ·çš„ç”»åƒï¼š
{context.long_term_memory.user_profile if context.long_term_memory else "æ— "}

ç”¨æˆ·çš„ä¹ æƒ¯å’Œåå¥½ï¼š
{context.long_term_memory.preferences if context.long_term_memory else "æ— "}
"""
